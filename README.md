# Create a scrapper and ETL process using Python, Selenium

## Description
From a website that use JavaScript, we will first create some instructions on a Jupyter Notebook to test a scrapper to get all the data from that site.

---

## Important
The website data are confidential because is from an intranet site.
So, the real url is on a secret **config.yaml** production file.
This file defines where are the urls, the XPath strings, titles and body from that site.

In GitHub there is only a **config.example.yaml** with dummy data.
Check first the configuration on this example file.

Example *config.example.yaml*:
```cmd
website_data:
  url: http://1.1.1.1/site/
  user: usuario
  password: pwd
  tags:
    tag_bntAceptarLogin: "tag_name"
    ...
```
---

This project use:
- Python
- Selenium
- Jupyter Notebook

## About the intranet example_site




## Installation

### Clone this repo

```cmd
git clone git@github.com:FernandoTorresL/admin_users.git
```

You can use and change *<my_folder>* on this instruction to create a new folder instead of the default *admin_users*

```cmd
git clone git@github.com:FernandoTorresL/admin_users.git <my_folder>
```

### How to test Web Scrapper

- WORK IN PROGRESS

---

## Test some particular ETL process

- WORK IN PROGRESS

### Transform process

- WORK IN PROGRESS

### Load process

- WORK IN PROGRESS

---

## Follow me

### [fertorresmx.dev](https://www.fertorresmx.dev/)

#### :globe_with_meridians: Twitter, Instagram: [@fertorresmx](http://www.twitter/fertorresmx)

